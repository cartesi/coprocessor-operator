
networks:
  coprocessor-network:
    name: coprocessor-network
    driver: bridge

secrets:
  operator1_bls_private_key:
    file: ./operator1_bls_private_key

services:
  operator1:
    secrets:
      - source: operator1_bls_private_key
        target: bls_private_key
    environment:
      - DB_DIRECTORY=/db
      - SNAPSHOT_DIR=/snapshots
      - LLAMA_SERVER=http://llama-server:8080
      - OPERATOR_ADDRESS=http://0.0.0.0:3033
      - MACHINE_HASH=ed62de75482451ae6c013b00466d5c52648c38f2e4efa383b5a2cc31864e5fe2
    ports:
      - "4001:4001/udp"
      - "4001:4001/tcp"
      - "3033:3033/tcp"
    image: ghcr.io/zippiehq/cartesi-coprocessor-operator:latest
    container_name: coprocessor-operator1
    volumes:
      - ./operator1-ipfs:/data
      - ./operator1-snapshots:/snapshots
      - ./operator1-db:/db
    networks:
      - coprocessor-network
    cap_drop:
        - ALL
    healthcheck:
      test: bash -c "[ cat < /dev/null > /dev/tcp/0.0.0.0/3033 ]"
      interval: 10s
      retries: 200
      start_period: 15s

  llama-server:
    image: ghcr.io/ggerganov/llama.cpp:server
    container_name: llama-server
    volumes:
      - ./llama/models:/llama/models
    command: -m /llama/models/Phi-3-mini-4k-instruct-q4.gguf -c 2048
    profiles:
      - llm
    healthcheck:
     test: ["CMD", "curl", "-f", "http://127.0.0.1:8080/health"]
     interval: 10s
     retries: 200
     start_period: 10s