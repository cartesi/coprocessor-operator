networks:
  coprocessor-network:
    name: coprocessor-network
    driver: bridge

secrets:
  operator1_bls_private_key:
    file: ./operator1_bls_private_key

services:
  operator1:
    secrets:
      - source: operator1_bls_private_key
        target: bls_private_key
    environment:
      - DB_DIRECTORY=/db
      - SNAPSHOT_DIR=/snapshots
      - LLAMA_SERVER=http://llama-server:8080
    ports:
      - "4001:4001/udp"
      - "4001:4001/tcp"
      - "3033:3033/tcp"
    image: ghcr.io/zippiehq/cartesi-coprocessor-operator:latest
    container_name: coprocessor-operator1
    volumes:
      - ./operator1-ipfs:/data
      - ./operator1-snapshots:/snapshots
      - ./operator1-db:/db
    depends_on:
      llama-server:
        condition: service_healthy
    networks:
      - coprocessor-network
    cap_drop:
        - ALL
    healthcheck:
      test: bash -c "[ cat < /dev/null > /dev/tcp/0.0.0.0/3033 ]"
      interval: 10s
      retries: 200
      start_period: 15s

  llama-server:
    image: ghcr.io/ggerganov/llama.cpp:server
    container_name: llama-server
    ports:
      - "8080:8080"
    volumes:
      - ./llama/models:/llama/models
    command: -m /llama/models/Phi-3-mini-4k-instruct-q4.gguf -c 2048
    healthcheck:
     test: ["CMD", "curl", "-f", "http://127.0.0.1:8080/health"]
     interval: 10s
     retries: 200
     start_period: 10s